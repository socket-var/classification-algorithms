{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do oversampling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import competition_helpers\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418, 100) (418, 1) (378, 100)\n",
      "[(0, 107), (1, 311)]\n",
      "[(0, 311), (1, 311)]\n"
     ]
    }
   ],
   "source": [
    "# I/O configuration here\n",
    "X_train = competition_helpers.read_csv(\"train_features.csv\")\n",
    "y_train = competition_helpers.read_csv(\"train_label.csv\", remove_header=True)\n",
    "X_test = competition_helpers.read_csv(\"test_features.csv\")\n",
    "submission_col = np.array(pd.read_csv(\"test_features.csv\", header=None).iloc[: , 0]).ravel()\n",
    "submission_file_name = \"results/voting_default_submission1.csv\"\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape)\n",
    "print(sorted(Counter(list(y_train.flatten())).items()))\n",
    "\n",
    "X_resampled, y_resampled = SMOTE().fit_resample(X_train, y_train.ravel())\n",
    "print(sorted(Counter(list(y_resampled.flatten())).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 fold cross validation\n",
    "# train_test_split = competition_helpers.kfold_stratified_split(X_train, y_train, 5,False)\n",
    "# With standardization\n",
    "standardized_train_test_split = competition_helpers.kfold_stratified_split(X_resampled, y_resampled.reshape((-1, 1)), 5,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # 5 fold train test split results\n",
    "# results = []\n",
    "# for estimators_ in [50, 100, 150]:\n",
    "#     for lr in [0.1, 0.5, 1, 5]:\n",
    "#         for [(X_train_cv, y_train_cv), (X_test_cv, y_test_cv)] in train_test_split:\n",
    "\n",
    "#             clf = AdaBoostClassifier(random_state=42,\n",
    "#                                     base_estimator=tree.DecisionTreeClassifier(\n",
    "#                                     max_depth=None, min_samples_split=60, min_samples_leaf= 30\n",
    "#                                     ),\n",
    "#                                      n_estimators=estimators_,\n",
    "#                                      learning_rate=lr\n",
    "#                                     )\n",
    "#             clf.fit(X_train_cv, y_train_cv.ravel())  \n",
    "#             prediction = clf.predict(X_test_cv)\n",
    "\n",
    "#             accuracy = accuracy_score(y_test_cv.ravel(), prediction.ravel())\n",
    "#             precision = precision_score(y_test_cv.ravel(), prediction.ravel())\n",
    "#             recall = recall_score(y_test_cv.ravel(), prediction.ravel())\n",
    "#             f1 = f1_score(y_test_cv.ravel(), prediction.ravel())\n",
    "\n",
    "#             results.append([accuracy, precision, recall, f1])\n",
    "\n",
    "\n",
    "#         measures = np.sum(np.array(results), axis=0) / len(results) \n",
    "#         print(\"n_estimators: {} learning rate: {} measures: {}\".format(estimators_, lr, measures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for [(X_train_cv, y_train_cv), (X_test_cv, y_test_cv)] in standardized_train_test_split:\n",
    "    \n",
    "\n",
    "    clf = BaggingClassifier(base_estimator=tree.DecisionTreeClassifier(), n_estimators=100)\n",
    "    clf.fit(X_train_cv, y_train_cv.ravel())  \n",
    "    prediction = clf.predict(X_test_cv)\n",
    "\n",
    "    accuracy = accuracy_score(y_test_cv.ravel(), prediction.ravel())\n",
    "    precision = precision_score(y_test_cv.ravel(), prediction.ravel())\n",
    "    recall = recall_score(y_test_cv.ravel(), prediction.ravel())\n",
    "    f1 = f1_score(y_test_cv.ravel(), prediction.ravel())\n",
    "\n",
    "    results.append([accuracy, precision, recall, f1])\n",
    "\n",
    "\n",
    "measures = np.sum(np.array(results), axis=0) / len(results) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8827701  0.87514141 0.89395801 0.884238  ]\n"
     ]
    }
   ],
   "source": [
    "print(measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting the test dataset\n",
    "\n",
    "\n",
    "clf = BaggingClassifier(base_estimator=tree.DecisionTreeClassifier(), n_estimators=100)\n",
    "\n",
    "clf.fit(X_resampled, y_resampled.ravel())  \n",
    "prediction = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"id\": submission_col, \"label\": prediction}).to_csv(submission_file_name, encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
